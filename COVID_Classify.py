
"""CT_Classify (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z07p6apWajDBbLYwBnK1L56sCeaCHn5x
"""

import torch
import torch.nn as nn
import torchvision
from torch.utils.data import DataLoader
import numpy as np
import torch.optim as optim
import matplotlib.pyplot as plt
import torchvision.transforms as transforms
from tools.dataload import CovidCTDataset
# %matplotlib inline



normlize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])

train_tf = transforms.Compose([
    transforms.Resize(256),
    transforms.RandomResizedCrop((224), scale=(0.5, 1.0)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    normlize
])

val_tf = transforms.Compose([
    transforms.Resize(224),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    normlize
])

BATCH_SIZE = 32
EPOCH = 100
LR = 0.05

trainset = CovidCTDataset(root_dir='./images/', 
                          txt_COVID='./data/COVID/trainCT_COVID.txt', 
                          txt_NonCOVID='./data/NonCOVID/trainCT_NonCOVID.txt',
                          transform=train_tf)
valset = CovidCTDataset(root_dir='./images/', 
                        txt_COVID='./data/COVID/valCT_COVID.txt', 
                        txt_NonCOVID='./data/NonCOVID/valCT_NonCOVID.txt', 
                        transform=val_tf)
testset = CovidCTDataset(root_dir='./images/',
                         txt_COVID='./data/COVID/testCT_COVID.txt',
                         txt_NonCOVID='./data/NonCOVID/testCT_NonCOVID.txt',
                         transform=val_tf)

train_loader = DataLoader(trainset, batch_size=BATCH_SIZE, drop_last=False, shuffle=True)
val_loader = DataLoader(valset, batch_size=BATCH_SIZE, drop_last=False, shuffle=False)
test_loader = DataLoader(testset, batch_size=BATCH_SIZE, drop_last=False, shuffle=False)

import torchxrayvision as  xrv

device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')
model = xrv.models.DenseNet(num_classes=2, in_channels=3).to(device)
model_name = 'DenseNet_medical'

torch.cuda.empty_cache()

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=LR)

def train(optimizer, epoch, model, train_loader, modelname, criterion):
    model.train()
    train_loss = 0
    train_correct = 0
    
    for batch_index, batch_samples in enumerate(train_loader):
        data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)
        
        output = model(data)
        loss = criterion(output, target.long())
        train_loss += loss
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        pred = output.argmax(dim=1, keepdim=True)
        train_correct += pred.eq(target.long().view_as(pred)).sum().item()
        
    print('avg_loss of train:{:.4f}, train_acc:{}/{}({:.0f}%)'.format(train_loss / len(train_loader.dataset),
                                    train_correct, len(train_loader.dataset),
                                    100 * train_correct / len(train_loader.dataset)))
    
    return train_loss / len(train_loader.dataset)


import torch.nn.functional as F

def val(model, val_loader, criterion):
    model.eval()
    val_loss, correct = 0, 0
    
    with torch.no_grad():
        predlist, scorelist, targetlist = [], [], []
        for batch_index, batch_samples in enumerate(val_loader):
            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)
            
            output = model(data)
            val_loss += criterion(output, target)
            score = F.softmax(output, dim=1)
            
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.long().view_as(pred)).sum().item()
            
            predlist = np.append(predlist, pred.cpu().numpy())
            scorelist = np.append(scorelist, score.cpu().numpy()[:, 1])
            targetlist = np.append(targetlist, target.long().cpu().numpy())
            
        print('val_acc:{}/{}({:.0f}%)'.format(correct, len(val_loader.dataset),
                                    100 * correct / len(val_loader.dataset)))
    
    return predlist, scorelist, targetlist, val_loss / len(val_loader.dataset)

def test(model, test_loader):
    model.eval()
    correct = 0
    
    with torch.no_grad():
        predlist, scorelist, targetlist = [], [], []
        for batch_index, batch_samples in enumerate(val_loader):
            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)
            
            output = model(data)
            score = F.softmax(output, dim=1)
            
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.long().view_as(pred)).sum().item()
            
            predlist = np.append(predlist, pred.cpu().numpy())
            scorelist = np.append(scorelist, score.cpu().numpy()[:, 1])
            targetlist = np.append(targetlist, target.long().cpu().numpy())
            
        print('test_acc:{}/{}({:.0f}%)'.format(correct, len(test_loader.dataset),
                                    100 * correct / len(test_loader.dataset)))
    
    
    return targetlist, scorelist, predlist

for epoch in range(EPOCH):
    
    print('Epoch: ', epoch)
    
    train_loss = train(optimizer, epoch, model, train_loader, model_name, criterion)
    predlist, scorelist, targetlist, val_loss = val(model, val_loader, criterion)
    
#     print('Target: ', targetlist)
#     print('Score: ', scorelist)
#     print('Predict: ', predlist)
   
    
    if (epoch+1) % 5 == 0:
        torch.save(model.state_dict(), 'covid_detection.pt')

targetlist, scorelist, predlist = test(model, test_loader)

# print('Target: ', targetlist)
# print('Score: ', scorelist)
# print('Predict: ', predlist)

